?dist
>hclust
?hclust
setwd("C:/Users/Usman shah/OneDrive/Desktop/INFO304/Assignment1/Assn1(2)")
##########################################################################
# sp500.r
##########################################################################
# Load time series and stock data libraries
##########################################################################
# NOTE: Just run the install.packages ONCE!
############################################
# install.packages("DMwR")
#############################################
library(xts)
library(DMwR)
library(quantmod)
#
# Read the csv file with sp500 data and convert to a time series object
########################################################################
sp500 <- as.xts(read.zoo("sp500.csv",header=T))
chartSeries(last(sp500,"1 months"), theme='white')
## 1. Describe what the candles are showing?
#shows Last assoasiated with how long the dta will last
chartSeries(last(sp500,"1 months"), theme='white')
head(sp500)
## 2. The daily average price can be approximated by:(high+close+low)/3
## code for the daily average price and plot at the end.
high <- sp500[,2] # select the second column for high.
close <- sp500[,4] # select the 4th column for the close.
low <- sp500[,3] # select the 3rd column for low.
head(close)
average <- (high+close+low)/3 # Average for the data.
sp500$average <- c(average) # Add the average column to the data.
plot(average, main = "Plot for the Average", ylab = "Average",col = "red") # Plot the result
previousDay <- close[-1] # get c(t-1), which is the close for the previous date.
dailyReturns <- as.numeric(close)# make it numeric values.
# Calculate the daily return
dailyReturns[2:length((dailyReturns))] <-
(dailyReturns[2:length((dailyReturns))] - dailyReturns[1:length((dailyReturns) - 1)])/dailyReturns[1:length((dailyReturns) - 1)]
head(dailyReturns[2:length((dailyReturns))])
head(dailyReturns)
sp500$return <- dailyReturns # Adding a column to the data for our dailyreturn
plot(last(sp500$return, "12 months")) # plot the dailyreturn for the last 12 months.
chartSeries(last(sp500,"12 months"), theme='white') # Candlechart for the last 12 months.
plot(last(sp500$return, "12 months")) # plot the dailyreturn for the last 12 months.
chartSeries(last(sp500,"12 months"), theme='white') # Candlechart for the last 12 months.
## 1. Describe what the candles are showing?
#shows Last assoasiated with how long the dta will last
chartSeries(last(sp500,"1 months"), theme='white')
## 1. Describe what the candles are showing?
#shows Last assoasiated with how long the dta will last
chartSeries(last(sp500,"12 months"), theme='white')
## 1. Describe what the candles are showing?
#shows Last assoasiated with how long the dta will last
chartSeries(last(sp500,"1 months"), theme='white')
chartSeries(last(sp500,"12 months"), theme='white') # Candlechart for the last 12 months.
data <- read.csv("network.csv",header=TRUE, sep=",")
head(data)
#2: What is the maximum and minimum degree for this network?
max(data$k)
# Tha maximum degree is 183.
min(data$k)
# The minimum degree is 5.
# 3: Produce a single figure showing two plots: the histogram of the degree,
# and a line plot sorted by degree. Comment on what this tells you about the network.
par(mfrow = c(1, 2))
hist(data$k, xlab = "Degree")
plot(sort(x = data$k), y = NULL, type = "l",main = "Plot soreted by degree", ylab = "Degree", col = "blue")
plot(x = data$k, y = NULL, type = "l",main = "Plot soreted by degree", ylab = "Degree", col = "blue")
)
plot(sort(x = data$k), y = NULL, type = "l",main = "Plot soreted by degree", ylab = "Degree", col = "blue")
#
# Assume we are given a table with a single response variable
# Want to make a table with the (x) and (y) values as 2 columns
#
# IN: d - the dataframe or matrix
#     response.var - the number of the column used as the response variable.  Defaults to last column
# OP: Calculates the normalised distance between each pair of data items in explanatory space
#     and the distance between their response variables.
# OUT: Data frame with 2 columns, the distance in feature space (x), and distance in response space (y)
########################################################################################################
dist.table <- function(d, response.var = ncol(d))
{
d <- scale(d) # scale data
d.dist <- dist(d[,-response.var])  # distance all X values
d.resp <- dist(d[,response.var])
d.dist <- (d.dist-min(d.dist))/(max(d.dist)-min(d.dist))
d.resp <- (d.resp-min(d.resp))/(max(d.resp)-min(d.resp))
data.frame(cbind(d.dist,d.resp))
}
#
# Example with simple linear response, random X1 and X2 but no noise for response
#
X1 <- runif(100)
X2 <- runif(100)
Y <- X1 + X2
#
ex1 <- data.frame(cbind(X1,X2,Y))
d <- dist.table(ex1, response.var = 3)
plot(x=d$d.dist, y = d$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5)
#X1 <- runif(100)
#X2 <- runif(100)
Y1 <- runif(100)
ex1 <- data.frame(cbind(X1,X2,Y1))
d <- dist.table(ex1, response.var = 3)
plot(x=d$d.dist, y = d$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5)
## 3: Produce figure with two plots using Boston housing dataset and ##
library("MASS")
data("Boston", package = "MASS")
dataBoston<-Boston
medvCol <- which(colnames(dataBoston)=="medv")
print(medvCol)
db <- dist.table(dataBoston,response.var = medvCol)
par(mfrow = c(1, 2))
plot(x=db$d.dist, y = db$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5)
dataBio <-read.table("bioavailability.txt")
lastColumn <- ncol(dataBio)
dc <- dist.table(dataBio,response.var = lastColumn)
plot(x=dc$d.dist, y = dc$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5)
#
# Assume we are given a table with a single response variable
# Want to make a table with the (x) and (y) values as 2 columns
#
# IN: d - the dataframe or matrix
#     response.var - the number of the column used as the response variable.  Defaults to last column
# OP: Calculates the normalised distance between each pair of data items in explanatory space
#     and the distance between their response variables.
# OUT: Data frame with 2 columns, the distance in feature space (x), and distance in response space (y)
########################################################################################################
dist.table <- function(d, response.var = ncol(d))
{
d <- scale(d) # scale data
d.dist <- dist(d[,-response.var])  # distance all X values
d.resp <- dist(d[,response.var])
d.dist <- (d.dist-min(d.dist))/(max(d.dist)-min(d.dist))
d.resp <- (d.resp-min(d.resp))/(max(d.resp)-min(d.resp))
data.frame(cbind(d.dist,d.resp))
}
#
# Example with simple linear response, random X1 and X2 but no noise for response
#
X1 <- runif(100)
X2 <- runif(100)
Y <- X1 + X2
#
ex1 <- data.frame(cbind(X1,X2,Y))
d <- dist.table(ex1, response.var = 3)
plot(x=d$d.dist, y = d$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "red")
plot(x=d$d.dist, y = d$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "dark")
plot(x=d$d.dist, y = d$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "yellow")
#X1 <- runif(100)
#X2 <- runif(100)
Y1 <- runif(100)
ex1 <- data.frame(cbind(X1,X2,Y1))
d <- dist.table(ex1, response.var = 3)
plot(x=d$d.dist, y = d$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "red")
plot(x=d$d.dist, y = d$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "pink")
plot(x=d$d.dist, y = d$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "red")
## 3: Produce figure with two plots using Boston housing dataset and bioavailibility##
library("MASS")
data("Boston", package = "MASS")
dataBoston<-Boston
medvCol <- which(colnames(dataBoston)=="medv")
print(medvCol)
db <- dist.table(dataBoston,response.var = medvCol)
plot(x=db$d.dist, y = db$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "red")
dataBio <-read.table("bioavailability.txt")
lastColumn <- ncol(dataBio)
dc <- dist.table(dataBio,response.var = lastColumn)
plot(x=dc$d.dist, y = dc$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "yellow")
plot(x=db$d.dist, y = db$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "black")
plot(x=db$d.dist, y = db$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "red")
## 3: Produce figure with two plots using Boston housing dataset and bioavailibility##
library("MASS")
data("Boston", package = "MASS")
dataBoston<-Boston
medvCol <- which(colnames(dataBoston)=="medv")
print(medvCol)
db <- dist.table(dataBoston,response.var = medvCol)
par(mfrow = c(1, 2))
plot(x=db$d.dist, y = db$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "red")
dataBio <-read.table("bioavailability.txt")
lastColumn <- ncol(dataBio)
dc <- dist.table(dataBio,response.var = lastColumn)
plot(x=dc$d.dist, y = dc$d.resp,xlab="Normalised Distance in Feature Space",
ylab="Normalised Distance in Response Space",cex=0.5,col = "yellow")
?dist
## VISUALIZATION AND VISUALIZATION
# Tell R about the packages you are using.
library("lattice")
library("tsne")
data = read.csv("countrystats.csv", header=T, sep=",") #Read the data from the file.
head(data)
#change the row name to be the country name
row.names(data)<-data[,1]
row.names(data)
#Delete the country name coloumn, which is the firsr coulumn.
data <- data[,-1]
head(data)
rowNames <-row.names(data)
# 3. Scale the data and create a distance matrix
dataDist <-dist(scale(data))
# Hierarchical clustered dendrogram with average algorithmative method.
dataDend <-hclust(dataDist,method="average")
plot(dataDend, main = "Hirarciahl clustered dendrogram with average", xlab = "country")
# Hierarchical clustered dendrogram with complete algorithmative method.
dataCom <-hclust(dataDist,method="complete")
plot(dataCom,main = "Hirarciahl clustered dendrogram with average", xlab = "country")
# Cut the dendrogram into 50 clusters
clusters <- cutree(dataCom, k = 50)
class(clusters)
is.recursive(clusters)
unique(clusters)
similarNz <- which(row.names(data)=="NewZealand")
print(similarNz)
## Using dimentionaly reduction method t-SNE to create a 2 dimentional plot of the data.
# Since we are
tsnee <- tsne(data, initial_config = NULL, k = 2,
max_iter = 50, min_cost = 0, epoch_callback = NULL, whiten = TRUE,
epoch=100)
plot(tsnee, main = "t-SNE Plot", xlab = "Dimension 2", ylab = "Dimension 2")
## VISUALIZATION AND VISUALIZATION
# Tell R about the packages you are using.
library("lattice")
library("tsne")
data = read.csv("countrystats.csv", header=T, sep=",") #Read the data from the file.
head(data)
#change the row name to be the country name
row.names(data)<-data[,1]
row.names(data)
#Delete the country name coloumn, which is the firsr coulumn.
data <- data[,-1]
head(data)
rowNames <-row.names(data)
# 3. Scale the data and create a distance matrix
dataDist <-dist(scale(data))
# Hierarchical clustered dendrogram with average algorithmative method.
dataDend <-hclust(dataDist,method="average")
plot(dataDend, main = "Hirarciahl clustered dendrogram with average", xlab = "country")
# Hierarchical clustered dendrogram with complete algorithmative method.
dataCom <-hclust(dataDist,method="complete")
plot(dataCom,main = "Hirarciahl clustered dendrogram with average", xlab = "country")
# Cut the dendrogram into 50 clusters
clusters <- cutree(dataCom, k = 50)
class(clusters)
is.recursive(clusters)
unique(clusters)
similarNz <- which(row.names(data)=="NewZealand")
print(similarNz)
## Using dimentionaly reduction method t-SNE to create a 2 dimentional plot of the data.
# Since we are
tsnee <- tsne(data, initial_config = NULL, k = 2,
max_iter = 50, min_cost = 0, epoch_callback = NULL, whiten = TRUE,
epoch=100)
plot(tsnee, main = "t-SNE Plot", xlab = "Dimension 2", ylab = "Dimension 2")
text(x = tsnee[,1],y = tsnee[,2],labels=row.names(data))
## Using dimentionaly reduction method t-SNE to create a 2 dimentional plot of the data.
# Since we are
tsnee <- tsne(data, initial_config = NULL, k = 2,
max_iter = 50, min_cost = 0, epoch_callback = NULL, whiten = TRUE,
epoch=100)
plot(tsnee, main = "t-SNE Plot", xlab = "Dimension 2", ylab = "Dimension 2")
text(x = tsnee[,1],y = tsnee[,2],labels=row.names(data))
## Using dimentionaly reduction method t-SNE to create a 2 dimentional plot of the data.
# Since we are
tsnee <- tsne(data, initial_config = NULL, k = 2,
max_iter = 50, min_cost = 0, epoch_callback = NULL, whiten = TRUE,
epoch=100)
plot(tsnee, main = "t-SNE Plot", xlab = "Dimension 2", ylab = "Dimension 2")
text(x = tsnee[,1],y = tsnee[,2],labels=row.names(data))
plot(tsnee,main = "t-SNE Plot", xlab = "Dimension 2", ylab = "Dimension 2",xlim = c(-4,2),ylim =c(0,6))
text(x = tsnee[,1],y = tsnee[,2],labels=row.names(data))
plot(tsnee,main = "t-SNE Plot", xlab = "Dimension 2", ylab = "Dimension 2",xlim = c(-3,1),ylim =c(2,6))
text(x = tsnee[,1],y = tsnee[,2],labels=row.names(data))
data = read.csv("countrystats.csv", header=T, sep=",") #Read the data from the file.
head(data)
#change the row name to be the country name
row.names(data)<-data[,1]
row.names(data)
#Delete the country name coloumn, which is the firsr coulumn.
data <- data[,-1]
head(data)
rowNames <-row.names(data)
# 3. Scale the data and create a distance matrix
dataDist <-dist(scale(data))
# Hierarchical clustered dendrogram with average algorithmative method.
dataDend <-hclust(dataDist,method="average")
plot(dataDend, main = "Hirarciahl clustered dendrogram with average", xlab = "country")
# Hierarchical clustered dendrogram with complete algorithmative method.
dataCom <-hclust(dataDist,method="complete")
plot(dataCom,main = "Hirarciahl clustered dendrogram with average", xlab = "country")
# Cut the dendrogram into 50 clusters
clusters <- cutree(dataCom, k = 50)
class(clusters)
is.recursive(clusters)
unique(clusters)
haed(clusters)
head(clusters)
which(colnames(clusters) == "NewZealand")
which(colnames(clusters) = 15)
which(colnames(clusters) == 15)
similarNz <- which(row.names(data)=="NewZealand")
print(similarNz)
head(clusters)
clusters$cluster
clusters$cluster == 1
dataCom[clusters$cluster == 1]
dataCom[clusters == 1]
dataCom[cluster == 1]
dataCom[clusters == 1]
clusters < 5
clusters == 15
unique(clusters == 15)
which(clusters == 15)
# Cut the dendrogram into 50 clusters
clusters <- cutree(dataCom, k = 50)
which(row.names(data)=="NewZealand")
which(clusters == 15)
which(row.names(data)==115)
which(row.names(data)=="NewZealand")
row.names(15)
which(row.names(data)=="NewZealand")
clusters[115]
which(clusters == 15) # find other countries in the same cluster in Nz
head(data)
rowNames <-row.names(data)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius= sqrt(data$PopDensity/pi)> # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$PopDensity,data$IncomeperCapita, circles=popradius, inches=0.45, fg="white", bg="red", xlab="", ylab="")
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi)> # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$PopDensity,data$IncomeperCapita, circles=popradius, inches=0.45, fg="white", bg="red", xlab="", ylab="")
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$PopDensity,data$IncomeperCapita, circles=popradius, inches=0.45, fg="white", bg="red", xlab="", ylab="")
text(data$PopDensity, data$IncomeperCapita, data$PurchasingParity, cex=0.6)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$ChangeGDP,data$IncomeperCapita, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="", ylab="")
text(data$ChangeGDP, data$IncomeperCapita, data$PurchasingParity, cex=0.6)
head(data)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$ChangeGDP, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="", ylab="")
text(data$IncomeperCapita, data$IncomeperCapita, cex=0.6)
text(data$IncomeperCapita, data$IncomeperCapita, cex=0.6)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$ChangeGDP, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="", ylab="")
text(data$IncomeperCapita, data$ChangeGDP, cex=0.6)
# 3. Scale the data and create a distance matrix
dataDist <-dist(scale(data))
# Hierarchical clustered dendrogram with average algorithmative method.
dataDend <-hclust(dataDist,method="average")
plot(dataDend, main = "Hirarciahl clustered dendrogram with average", xlab = "country")
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
dataScaled<- scale(data)
data = read.csv("countrystats.csv", header=T, sep=",") #Read the data from the file.
head(data)
#change the row name to be the country name
row.names(data)<-data[,1]
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$ChangeGDP, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="", ylab="")
text(data$IncomeperCapita, data$ChangeGDP,data$Country cex=0.6)
text(data$IncomeperCapita, data$ChangeGDP,data$Country ,cex=0.6)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$ChangeGDP, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="IncomePerCapita", ylab="changeGDP")
text(data$IncomeperCapita, data$ChangeGDP,data$Country ,cex=0.6)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$PopDensity/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$PurchasingParity,data$ChangeGDP, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="IncomePerCapita", ylab="changeGDP")
text(data$PurchasingParity, data$ChangeGDP,data$Country ,cex=0.6)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$ChangeGDP/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$PopDensity,data$IncomeperCapita, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="popDensity", ylab="Incomepercapita")
text(data$PopDensity, data$IncomeperCapita,data$Country ,cex=0.6)
head(data)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$ChangeGDP/pi) # circles are done as the radius, so we calculate the radius so that> # the symbols are proportional in area to the population size
symbols(data$PurchasingParity,data$PopDensity, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="purchasingParity", ylab="popdensity")
text(data$PurchasingParity, data$PopDensity,data$Country ,cex=0.6)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$ChangeGDP/pi) # circles are done as the radius, so we calculate the radius so that
# the symbols are proportional in area to the population size
symbols(data$PopDensity,data$PurchasingParity, circles=popradius,
inches=0.45, fg="white", bg="red", xlab="purchasingParity", ylab="popdensity")
text(data$PopDensity, data$PurchasingParity,data$Country ,cex=0.2)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$ChangeGDP/pi) # circles are done as the radius, so we calculate the radius so that
# the symbols are proportional in area to the population size
symbols(data$PopDensity,data$PurchasingParity, circles=popradius,
inches=0.20, fg="white", bg="red", xlab="purchasingParity", ylab="popdensity")
text(data$PopDensity, data$PurchasingParity,data$Country ,cex=0.6)
# the symbols are proportional in area to the population size
symbols(data$PopDensity,data$PurchasingParity, circles=popradius,
inches=0.60, fg="white", bg="red", xlab="purchasingParity", ylab="popdensity")
text(data$PopDensity, data$PurchasingParity,data$Country ,cex=0.6)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$ChangeGDP/pi) # circles are done as the radius, so we calculate the radius so that
# the symbols are proportional in area to the population size
symbols(data$PopDensity,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red", xlab="purchasingParity", ylab="popdensity")
text(data$PopDensity, data$PurchasingParity,data$Country ,cex=0.6)
# the symbols are proportional in area to the population size
symbols(data$PopDensity,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red", xlab="purchasingParity", ylab="popdensity")
text(data$Country ,cex=0.6)
text(data$PopDensity, data$PurchasingParity,data$Country ,cex=0.6)
# the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red", xlab="purchasingParity", ylab="popdensity")
text(data$IncomeperCapita, data$PurchasingParity,data$Country ,cex=0.6)
# 2. Which country look similar to New Zealand? Which country is the strongges or the weekest?
popradius<-sqrt(data$ChangeGDP/pi) # circles are done as the radius, so we calculate the radius so that
# the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red", xlab="Income Per Cpita", ylab="Purchasing Parity")
text(data$IncomeperCapita, data$PurchasingParity,data$Country ,cex=0.6)
# the symbols are proportional in area to the population size
symbols(data$PopDensity,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red", xlab="Population Density", ylab="Purchasing Parity")
text(data$PopDensity, data$PurchasingParity,data$Country ,cex=0.6)
# the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red", xlab="Income Per Cpita", ylab="Purchasing Parity")
text(data$IncomeperCapita, data$PurchasingParity,data$Country ,cex=0.6)
# the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red",main = "Bubble Plot for country economy", xlab="Income Per Cpita", ylab="Purchasing Parity")
text(data$IncomeperCapita, data$PurchasingParity,data$Country ,cex=0.6)
head(data)
# the symbols are proportional in area to the population size
symbols(data$PopDensity,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red",main = "Bubble Plot for country economy", xlab="Income Per Cpita", ylab="Purchasing Parity")
text(data$PopDensity, data$PurchasingParity,data$Country ,cex=0.6)
# the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red",main = "Bubble Plot for country economy", xlab="Income Per Cpita", ylab="Purchasing Parity")
text(data$IncomeperCapita, data$PurchasingParity,data$Country ,cex=0.6)
data = read.csv("countrystats.csv", header=T, sep=",")
popradius<-sqrt(data$ChangeGDP/pi) # circles are done as the radius, so we calculate the radius so that
# the symbols are proportional in area to the population size
symbols(data$IncomeperCapita,data$PurchasingParity, circles=popradius,
inches=0.40, fg="white", bg="red",main = "Bubble Plot for country economy", xlab="Income Per Cpita", ylab="Purchasing Parity")
text(data$IncomeperCapita, data$PurchasingParity,data$Country ,cex=0.6)
head(data)
